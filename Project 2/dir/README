NAME: Chaoran Lin
EMAIL: linmc@ucla.edu
ID: 004674598

Included files
==============

lab2_add.c is a C program that implements and tests a shared variable add function
with options of yielding and multiple lock mechanisms, and produces a CSV output
of statistics.

lab2_list.c is a C program that implements and tests a shared list mainpulation function
with options of yielding and multiple lock mechanisms, and produces a CSV output
of statistics.

SortedList.h is a header file describing the interfaces for linked list.

SortedList.c is a C program that implements the interface specified in SortedList.h.

Makefile contains commands to make, test, graph, create a tarball distribution,
and clean the directory, restoring to its original state.

lab2_add.csv contains all the results of the lab2_add tests.

lab2_list.csv contains all the results of the lab2_list tests.

test.sh is a bash script that runs all the tests and outputs to their csvs.

lab2_add.gp and lab2_list.gp take the csv files and organize
their data into relevant graphs.

lab2_add-1.png is a graph describing the threads and iterations
required to generate a failure (with and without yields).

lab2_add-2.png is a graph describing average time per operation with and without yields.

lab2_add-3.png is a graph describing average time per (single threaded)
operation vs. the number of iterations.

lab2_add-4.png is a graph describing threads and iterations that can
run successfully with yields under each of the synchronization options.

lab2_add-5.png is a graph describing average time per (protected)
operation vs. the number of threads.

lab2_list-1.png is a graph describing average time per (single threaded)
unprotected operation vs. number of iterations (illustrating the correction
of the per-operation cost for the list length).

lab2_list-2.png is a graph describing threads and iterations required
to generate a failure (with and without yields).

lab2_list-3.png is a graph describing iterations that can run (protected)
without failure.

lab2_list-4.png is a graph describing (length-adjusted) cost per operation
vs the number of threads for the various synchronization options.


Answers to Questions 2.1-2.2
============================

QUESTION 2.1.1 - causing conflicts:

- Why does it take many iterations before errors are seen?

With many iterations, threads will modify the shared variable (in this case
the counter variable) more, and thus increasing the number of accesses to
the critical section. Since they must be interrupted during these accesses,
error occurrences are more frequent when these accesses/iterations increase.

- Why does a significantly smaller number of iterations so seldom fail?

Conversely, when we limit the number of iterations/accesses to the critical
section, there is less of a chance that each thread may be interrupted during
its access, resulting in less error.

===

QUESTION 2.1.2 - cost of yielding:

- Why are the --yield runs so much slower?

The --yield runs cause a switch between threads in the process, which dramatically
increases the performance overhead.

- Where is the additional time going?

The additional time goes to the CPU's switching between threads, i.e. a context
switch.

- Is it possible to get valid per-operation timings if we are using the --yield option?
If so, explain how. If not, explain why not.

No. Much of the CPU time is allocated to yielding, which is technically not a part
of the thread operations.

===

QUESTION 2.1.3 - measurement errors:

- Why does the average cost per operation drop with increasing iterations?

The average cost per operation is the runtime / number of operations, which
consists of iterations. With yielding, the cost per operation is extremely high
for one or a few operations because of the cost of context switching. However,
increasing the number of operations, while keeping the cost of context switching
relatively unchanged or hardly increasing between these operations, allows us
to lower the average cost per operation.

- If the cost per iteration is a function of the number of iterations, how do we
know how many iterations to run (or what the "correct" cost is)?

Based on the previous question, we know that the "correct" number of iterations to
run lies in a range slightly above 10.

===

QUESTION 2.1.4 - costs of serialization:

- Why do all of the options perform similarly for low numbers of threads?

If there is a low number of threads, then managing to keep one thread inside the
critical section and the others locked outside through mutual exclusion is a
relatively cheap task, whether it is achieved through making the other threads
spin or performing compare and swap operations, 

- Why do the three protected operations slow down as the number of threads rises?

Following from the previous response, we can imagine as the number of threads
rises, the number of threads that are excluded from the critical section
will reach a point where locking becomes very costly compared to when we had
a small number of threads.

===

QUESTION 2.2.1 - scalability of Mutex

- Compare the variation in time per mutex-protected operation vs the number of
threads in Part-1 (adds) and Part-2 (sorted lists).

- Comment on the general shapes of the curves, and explain why they have this shape.

The overall trends of the time per mutex-protected operations for Part-1 and Part-2
are quite similar in that the time/cost per protected operation increases overall
as the number of threads increases. As previously explained in 2.1.4, an increase
in the number of threads in our process means that the mutex mechanism must lock
and unlock more frequently and allow more threads to wait.

- Comment on the relative rates of increase and differences in the shapes of the
curves, and offer an explanation for these differences.

The overall rates of increase and differences in shape are, again, rather minor.
It is worthwhile pointing out that in Part-1, the time operation has a few
decreases along with increases, especially after 4 threads. This could be due to the
fact that the runtime does not increase fast enough for a certain number of
thread increases.

===

QUESTION 2.2.2 - scalability of spin locks

- Compare the variation in time per protected operation vs the number of threads for
list operations protected by Mutex vs Spin locks. Comment on the general shapes of
the curves, and explain why they have this shape.

The overall trends of the Mutex and Spin locks plot lines are quite similar in that
the time/cost per protected operation increases overall as the number of threads increases,
which is reasonable as previously explained in 2.1.4. 

- Comment on the relative rates of increase and differences in the shapes of the
curves, and offer an explanation for these differences.

We see that in the graph, its cost per operation always stays above that of mutexes.
This is because spin locks are generally considered more expensive than mutexes due
to their mechanism of letting threads spin outside of the critical section while
awaiting a thread inside it to exit.

======

List of references

https://computing.llnl.gov/tutorials/pthreads/
http://man7.org/linux/man-pages/man2/clock_gettime.2.html
http://www.geeksforgeeks.org/doubly-linked-list/
http://www.cplusplus.com/reference/cstring/strcmp/
